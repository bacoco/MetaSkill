# Synapse Output Format

Complete specification for `Synapse_RECOMMENDATIONS.md`.

## File Structure

```markdown
# Synapse Skill Recommendations

> Generated on YYYY-MM-DD HH:MM:SS
> Analysis period: Last N days
> Pattern threshold: N occurrences

---

## Summary

- **Total recommendations**: N
- **High priority**: N
- **Medium priority**: N
- **Low priority**: N

---

## Recommended Skills

### 1. ðŸ”´ skill-name

**Priority:** CRITICAL

**Pattern Type:** pattern_type

**Source:** Cortex patterns / PRD analysis / Task analysis

**Reason:** Brief explanation

**Frequency:** N.N times/day (N total)

**Example Contexts:**
- Context 1
- Context 2
- Context 3

---

### 2. ðŸŸ  another-skill

**Priority:** HIGH

...

---

## Next Steps

1. **Review** these recommendations
2. **Run auto-generator** to create high-priority skills:
   ```bash
   python .claude/skills/synapse/scripts/auto_skill_generator.py
   ```
3. **Test** generated skills with your workflow
4. **Synapse will continue monitoring** and update recommendations

---

*Generated by Synapse Unified Analyzer*
*Combining Cortex patterns, PRD analysis, and task analysis*
```

## Priority Icons

- ðŸ”´ **CRITICAL** - Immediate action recommended
- ðŸŸ  **HIGH** - Should generate soon
- ðŸŸ¡ **MEDIUM** - Generate when convenient
- ðŸŸ¢ **LOW** - Monitor for increase

## Recommendation Fields

### Required Fields

- **Priority**: CRITICAL / HIGH / MEDIUM / LOW
- **Pattern Type**: Type of pattern detected (api_call, data_processing, etc.)
- **Source**: Where the recommendation came from
- **Reason**: Why this skill is recommended
- **Frequency**: How often the pattern occurs

### Optional Fields

- **Example Contexts**: Sample occurrences from Cortex
- **PRD Tasks**: Related tasks from PRD files
- **Suggested Capabilities**: What the skill should do
- **Related Skills**: Existing skills that complement this one

## Source Types

### Cortex Patterns

```markdown
**Source:** Cortex patterns
**Pattern Type:** api_call
**Frequency:** 3.5 times/day (24 total)
**Example Contexts:**
- Called GitHub API for repos
- Called Stripe API for customers
- Called SendGrid API for emails
```

### PRD Analysis

```markdown
**Source:** PRD analysis
**Pattern Type:** testing
**Task Count:** 15 test-related tasks
**PRD Files:**
- PROJECT_PRD.md (8 tasks)
- TEST_REQUIREMENTS.md (7 tasks)
```

### Task Analysis

```markdown
**Source:** Task analysis
**Pattern Type:** deployment
**Task Count:** 8 deployment TODOs
**Task Sources:**
- TODO.md (5 tasks)
- ROADMAP.md (3 tasks)
```

### Combined Sources

```markdown
**Source:** Cortex patterns + PRD analysis
**Pattern Type:** data_processing
**Cortex Frequency:** 2.1 times/day (15 total)
**PRD Tasks:** 7 ETL tasks
**Combined Priority:** CRITICAL (merged from HIGH + MEDIUM)
```

## Example Output Files

### Minimal Output (No Recommendations)

```markdown
# Synapse Skill Recommendations

> Generated on 2025-10-26 10:00:00
> Analysis period: Last 7 days
> Pattern threshold: 5 occurrences

---

## Summary

- **Total recommendations**: 0
- **High priority**: 0
- **Medium priority**: 0
- **Low priority**: 0

---

## Recommended Skills

âœ… **No new skills needed** - existing skills cover current patterns.

## Next Steps

1. **Continue working** - Synapse will monitor for new patterns
2. **Synapse runs automatically** every 30 minutes (if configured)
3. **Check back later** for updated recommendations

---

*Generated by Synapse Unified Analyzer*
```

### Multiple Recommendations

```markdown
# Synapse Skill Recommendations

> Generated on 2025-10-26 10:00:00
> Analysis period: Last 7 days
> Pattern threshold: 5 occurrences

---

## Summary

- **Total recommendations**: 5
- **High priority**: 2
- **Medium priority**: 2
- **Low priority**: 1

---

## Recommended Skills

### 1. ðŸ”´ api-optimizer

**Priority:** CRITICAL

**Pattern Type:** api_call

**Source:** Cortex patterns

**Reason:** Detected 24 API operations in 7 days

**Frequency:** 3.4 times/day (24 total)

**Example Contexts:**
- GET /api/users - Called 8 times
- POST /api/auth - Called 6 times
- GET /api/data - Called 10 times

**Suggested Capabilities:**
- Rate limiting and retry logic
- Response caching with TTL
- Error handling patterns
- Request/response logging

---

### 2. ðŸ”´ data-transformer

**Priority:** CRITICAL

**Pattern Type:** data_processing

**Source:** Cortex patterns + PRD analysis

**Reason:** Frequent data transformation operations

**Cortex Frequency:** 2.1 times/day (15 total)

**PRD Tasks:** 7 ETL-related tasks in PROJECT_PRD.md

**Example Contexts:**
- Parsed CSV files (5 times)
- Transformed JSON responses (6 times)
- Validated data formats (4 times)

**Suggested Capabilities:**
- CSV/JSON/XML parsing
- Data validation and cleaning
- Format conversions
- Schema validation

---

### 3. ðŸŸ  test-guardian

**Priority:** HIGH

**Pattern Type:** testing

**Source:** PRD analysis

**Reason:** Large number of testing requirements

**Task Count:** 15 test-related tasks

**PRD Files:**
- PROJECT_PRD.md (8 tasks)
- TEST_REQUIREMENTS.md (7 tasks)

**Suggested Capabilities:**
- Test case generation
- Coverage analysis
- Mock data creation
- Test runner integration

---

### 4. ðŸŸ¡ deploy-sage

**Priority:** MEDIUM

**Pattern Type:** deployment

**Source:** Task analysis

**Reason:** Multiple deployment TODOs identified

**Task Count:** 8 deployment tasks

**Task Sources:**
- TODO.md (5 tasks)
- ROADMAP.md (3 tasks)

**Suggested Capabilities:**
- Docker container management
- CI/CD pipeline helpers
- Environment configuration
- Health check monitoring

---

### 5. ðŸŸ¢ docs-writer

**Priority:** LOW

**Pattern Type:** documentation

**Source:** Cortex patterns

**Reason:** Occasional documentation updates

**Frequency:** 0.4 times/day (3 total)

**Example Contexts:**
- Updated README.md
- Created API documentation
- Added inline comments

**Suggested Capabilities:**
- Markdown generation
- API docs from code
- Comment generation
- Documentation templates

---

## Next Steps

1. **Review** these recommendations
2. **Run auto-generator** to create high-priority skills:
   ```bash
   python .claude/skills/synapse/scripts/auto_skill_generator.py
   ```
3. **Test** generated skills with your workflow
4. **Synapse will continue monitoring** and update recommendations

---

*Generated by Synapse Unified Analyzer*
*Combining Cortex patterns, PRD analysis, and task analysis*
```

## Machine-Readable Format

Synapse can also output JSON for programmatic consumption:

```bash
python .claude/skills/synapse/scripts/synapse_analyzer.py --format json
```

```json
{
  "generated_at": "2025-10-26T10:00:00",
  "analysis_period_days": 7,
  "threshold": 5,
  "summary": {
    "total_recommendations": 5,
    "by_priority": {
      "critical": 2,
      "high": 1,
      "medium": 1,
      "low": 1
    }
  },
  "recommendations": [
    {
      "skill_name": "api-optimizer",
      "priority": "critical",
      "pattern_type": "api_call",
"source": "cortex_patterns",
      "frequency": 3.4,
      "count": 24,
      "reason": "Detected 24 API operations in 7 days",
      "contexts": ["GET /api/users", "POST /api/auth", ...]
    },
    ...
  ]
}
```

## Reading the Output

### For Humans

Read `Synapse_RECOMMENDATIONS.md` to understand:
- Which skills are recommended
- Why they're recommended
- What priority they have
- Whether to generate them

### For Claude

Claude reads the markdown file and:
- Identifies high-priority recommendations
- Uses skill-creator to generate skills
- Records generation in Cortex memory

### For Other LLMs

GPT, Gemini, etc. can read the markdown file:
```
Read Synapse_RECOMMENDATIONS.md and tell me what skills I should create
```

### For Scripts

Parse the JSON format for automated workflows:
```python
import json

with open("Synapse_RECOMMENDATIONS.json") as f:
    recs = json.load(f)

for rec in recs["recommendations"]:
    if rec["priority"] in ["critical", "high"]:
        print(f"Generate: {rec['skill_name']}")
```

## See Also

- [EXAMPLES.md](EXAMPLES.md) - Real-world examples
- [MANUAL_USAGE.md](MANUAL_USAGE.md) - Command-line options
- Main SKILL.md - Synapse overview
