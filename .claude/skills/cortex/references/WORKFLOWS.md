# Cortex Workflows

Common patterns for using Cortex effectively.

## Workflow 1: Automatic Session Tracking

Cortex tracks your work automatically via git hooks.

### Setup

```bash
cd .claude/skills/cortex/scripts
./install.sh
```

### What Gets Tracked

- **File changes** - Which files were modified and why
- **Git operations** - Commits, branches, merges
- **Task completions** - What was accomplished
- **Errors encountered** - Problems and their resolutions

### Viewing Session History

```bash
# Human-readable narrative
cat .cortex_log.md

# Machine-readable state
cat .cortex_status.json | jq .

# Next session quick start
cat .cortex_handoff.md
```

---

## Workflow 2: Agent Handoff

Transfer context between sessions seamlessly.

### End of Session

Cortex automatically generates `.cortex_handoff.md` with:
- Summary of work completed
- Current repository state
- Priority next steps
- Links to detailed logs

### Start of New Session

Claude automatically reads `.cortex_handoff.md` and knows:
- What was done previously
- Where you left off
- What to do next

**No manual intervention required** - handoffs are automatic.

---

## Workflow 3: Inter-Skill Communication

Skills share data through Cortex memory.

### Skill A: Record Data

```python
# In skill-a/scripts/main.py
from cortex_api import add_cortex_event

def process_data():
    result = expensive_computation()

    add_cortex_event("computation_result", "Computed user metrics", {
        "result_type": "user_metrics",
        "cached_at": datetime.now().isoformat(),
        "result": result
    })

    return result
```

### Skill B: Use Cached Data

```python
# In skill-b/scripts/main.py
from cortex_api import get_cortex_memory
from datetime import datetime, timedelta

def get_metrics():
    # Check if recent computation exists
    one_hour_ago = datetime.now() - timedelta(hours=1)
    recent = get_cortex_memory(
        filter_type="computation_result",
        since=one_hour_ago
    )

    if recent:
        # Use cached result
        return recent[0]["metadata"]["result"]
    else:
        # Recompute
        return expensive_computation()
```

---

## Workflow 4: Pattern-Based Skill Generation

Synapse uses Cortex to automatically create new skills.

### Automatic Flow

1. **You work normally** - Use Claude to complete tasks
2. **Cortex tracks patterns** - Records repeated operations
3. **Synapse analyzes** - Detects patterns above threshold
4. **Skills auto-generate** - When priority is high/critical
5. **You use new skill** - Automatically available

### Example: API Integration Skill

```python
# You call APIs manually several times
add_cortex_event("api_call", "Called Stripe API for customer data")
add_cortex_event("api_call", "Called Stripe API for invoices")
add_cortex_event("api_call", "Called Stripe API for subscriptions")
# ... 5 more times in 7 days ...

# Synapse detects pattern and auto-generates "stripe-api" skill
# Next time you mention Stripe, Claude uses the new skill
```

---

## Workflow 5: Error Pattern Detection

Track and learn from errors.

### Recording Errors

```python
from cortex_api import add_cortex_event

try:
    result = risky_operation()
except SpecificError as e:
    add_cortex_event("error", "Operation failed due to X", {
        "error_type": "SpecificError",
        "operation": "risky_operation",
        "context": str(e)
    })

    # Record the fix
    result = fallback_operation()
    add_cortex_event("error_resolved", "Used fallback successfully", {
        "original_error": "SpecificError",
        "solution": "fallback_operation"
    })
```

### Analyzing Error Patterns

```python
from cortex_api import get_cortex_memory

# Find all errors
errors = get_cortex_memory(filter_type="error", limit=50)

# Group by type
error_types = {}
for event in errors:
    error_type = event["metadata"].get("error_type", "unknown")
    error_types[error_type] = error_types.get(error_type, 0) + 1

# Identify frequent errors
for error_type, count in sorted(error_types.items(), key=lambda x: x[1], reverse=True):
    if count >= 3:
        print(f"⚠️ Frequent error: {error_type} ({count} times)")
```

If an error pattern occurs frequently, Synapse may recommend a skill to handle it.

---

## Workflow 6: Cross-Session Data Persistence

Use Cortex to persist data across sessions.

### Store Configuration

```python
from cortex_api import add_cortex_event

def save_config(config):
    add_cortex_event("config_saved", "Updated project configuration", {
        "config_version": "2.0",
        "settings": config
    })
```

### Retrieve Configuration

```python
from cortex_api import get_cortex_memory

def load_config():
    configs = get_cortex_memory(filter_type="config_saved", limit=1)
    if configs:
        return configs[0]["metadata"]["settings"]
    else:
        return default_config()
```

---

## Workflow 7: Performance Monitoring

Track performance metrics over time.

### Record Performance

```python
import time
from cortex_api import add_cortex_event

def monitored_function():
    start = time.time()

    result = expensive_operation()

    duration = time.time() - start

    add_cortex_event("performance", "Expensive operation completed", {
        "operation": "expensive_operation",
        "duration_seconds": duration,
        "items_processed": len(result)
    })

    return result
```

### Analyze Trends

```python
from cortex_api import get_cortex_memory
from datetime import timedelta, datetime

def analyze_performance():
    week_ago = datetime.now() - timedelta(days=7)
    metrics = get_cortex_memory(
        filter_type="performance",
        since=week_ago
    )

    durations = [m["metadata"]["duration_seconds"] for m in metrics]
    avg_duration = sum(durations) / len(durations) if durations else 0

    print(f"Average operation time: {avg_duration:.2f}s")

    if avg_duration > 5.0:
        print("⚠️ Performance degradation detected!")
        print("   Consider optimization or creating dedicated skill.")
```

---

## Workflow 8: Multi-Developer Coordination

Share context across developers using Cortex files.

### Developer A: End of Day

```bash
# Commit work + Cortex files
git add .
git commit -m "feat: Implemented user authentication

- Added login/logout endpoints
- Set up JWT tokens
- Tests passing"

git add .cortex_log.md .cortex_status.json .cortex_handoff.md
git commit -m "chore: Update Cortex session logs"

git push
```

### Developer B: Next Morning

```bash
git pull

# Read handoff
cat .cortex_handoff.md
```

Developer B immediately understands:
- What Developer A accomplished
- Current system state
- Recommended next steps
- Any blockers or notes

---

## Workflow 9: Task Continuity After Interruptions

Resume work seamlessly after breaks.

### Before Break

Cortex automatically records:
- Current task in progress
- Files being modified
- Tests that need to run
- Context about decisions made

### After Break

```bash
# Quick context refresh
cat .cortex_handoff.md
```

Claude reads this and knows:
- Where you left off
- What you were working on
- Next immediate steps

**No need to remember details** - Cortex remembers for you.

---

## Workflow 10: Debugging with Historical Context

Use Cortex history to debug issues.

### Find When Issue Started

```python
from cortex_api import get_cortex_memory
from datetime import datetime, timedelta

# Search for events around the time bug appeared
bug_time = datetime(2025, 10, 25, 14, 30)
window_start = bug_time - timedelta(hours=2)

events = get_cortex_memory(since=window_start)

print("Events before bug appeared:")
for event in events:
    print(f"  {event['timestamp']} - {event['description']}")
```

### Correlate Changes with Behavior

```bash
# Check what was changed around that time
cat .cortex_log.md | grep -A 5 "2025-10-25 14:"
```

Cortex's detailed logs help identify:
- Which file changes correlated with the bug
- What operations were attempted
- Any errors that occurred
- System state at that time

---

## Best Practices

1. **Let Cortex run automatically** - Don't disable git hooks unless necessary
2. **Use semantic event types** - Consistent naming enables pattern detection
3. **Include context in metadata** - More data = better pattern analysis
4. **Commit Cortex files regularly** - Enables team coordination
5. **Read handoffs at session start** - Quick context refresh saves time
6. **Trust the automation** - Synapse will create skills when patterns emerge

---

## Troubleshooting

### Cortex files not updating

```bash
# Check git hooks are installed
ls -la .git/hooks/post-commit

# Reinstall if needed
cd .claude/skills/cortex/scripts
./install.sh
```

### Cortex API import errors

```python
# Add to Python path
import sys
from pathlib import Path
sys.path.insert(0, str(Path(".claude/skills/cortex/scripts")))
from cortex_api import *
```

### Lock file conflicts

```bash
# Remove stale lock (only if no Cortex operations running)
rm -f .soul_lock
```

---

## See Also

- [API_REFERENCE.md](API_REFERENCE.md) - Complete API documentation
- [MULTI_LLM.md](MULTI_LLM.md) - Using Cortex with different LLMs
- Main SKILL.md - Cortex overview
